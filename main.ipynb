{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a0681eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ce2c284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_LbELtWX\\\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7f2ee6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "for i in data['id']:\n",
    "    path = 'train_LbELtWX\\\\train\\\\' + str(i) + '.png'\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img,(28,28))\n",
    "    X.append(img.astype('float32'))\n",
    "    \n",
    "X=np.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "25bfcafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1acd3e1f3d0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdcaf49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "921c27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a01398b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(tf.one_hot(Y,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3129645",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,Y_train,Y_val = train_test_split(X,Y,random_state=42,test_size=0.17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "092e7abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49800, 28, 28, 3), (49800, 10))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "80aa08e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= tf.keras.Sequential([\n",
    "# Model_1 Architecture\n",
    "#     layers.Conv2D(256,3,input_shape=(28,28,3),activation='relu'),\n",
    "#     layers.MaxPooling2D(2),\n",
    "#     layers.Conv2D(128,3,activation='relu'),\n",
    "#     layers.MaxPooling2D(2),\n",
    "    \n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(512,activation='relu'),\n",
    "#     layers.Dropout(0.2),\n",
    "#     layers.Dense(216,activation='relu'),\n",
    "#     layers.Dropout(0.2),\n",
    "#     layers.Dense(10,activation='softmax'),\n",
    "    \n",
    "# Model_2 Architecture\n",
    "#     layers.Conv2D(128,3,input_shape=(28,28,3),activation='relu'),\n",
    "#     layers.MaxPooling2D(2),\n",
    "#     layers.Conv2D(256,3,input_shape=(28,28,3),activation='relu'),\n",
    "#     layers.MaxPooling2D(3),\n",
    "    \n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(1024,activation='relu'),\n",
    "#     layers.Dropout(0.3),\n",
    "#     layers.Dense(512,activation='relu'),\n",
    "#     layers.Dropout(0.3),\n",
    "#     layers.Dense(128,activation='relu'),\n",
    "#     layers.Dropout(0.2),\n",
    "#     layers.Dense(10,activation='softmax'),\n",
    "\n",
    "# # Model_3 Architecture\n",
    "    layers.Conv2D(128,3,input_shape=(28,28,3),activation='relu'),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(256,3 ,activation='relu'),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256,activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10,activation='softmax'),\n",
    "    \n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b714fa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_52 (Conv2D)           (None, 26, 26, 128)       3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 11, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 256)               1638656   \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,939,978\n",
      "Trainable params: 1,939,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "26694429",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "765fd71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1557/1557 [==============================] - 538s 345ms/step - loss: 0.5451 - accuracy: 0.8056\n",
      "Epoch 2/10\n",
      "1557/1557 [==============================] - 550s 353ms/step - loss: 0.3719 - accuracy: 0.8676\n",
      "Epoch 3/10\n",
      "1557/1557 [==============================] - 517s 332ms/step - loss: 0.3218 - accuracy: 0.8847\n",
      "Epoch 4/10\n",
      "1557/1557 [==============================] - 514s 330ms/step - loss: 0.2864 - accuracy: 0.8961\n",
      "Epoch 5/10\n",
      "1557/1557 [==============================] - 508s 326ms/step - loss: 0.2640 - accuracy: 0.9039\n",
      "Epoch 6/10\n",
      "1557/1557 [==============================] - 552s 355ms/step - loss: 0.2427 - accuracy: 0.9127\n",
      "Epoch 7/10\n",
      "1557/1557 [==============================] - 618s 397ms/step - loss: 0.2247 - accuracy: 0.9172\n",
      "Epoch 8/10\n",
      "1557/1557 [==============================] - 601s 386ms/step - loss: 0.2080 - accuracy: 0.9248\n",
      "Epoch 9/10\n",
      "1557/1557 [==============================] - 565s 363ms/step - loss: 0.1924 - accuracy: 0.9310\n",
      "Epoch 10/10\n",
      "1557/1557 [==============================] - 578s 371ms/step - loss: 0.1787 - accuracy: 0.9336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1acd35a39d0>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dd88e61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319/319 [==============================] - 34s 104ms/step - loss: 0.2359 - accuracy: 0.9131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23592843115329742, 0.9131372570991516]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_val,Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cd0424de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_4.model',save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f5dd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
